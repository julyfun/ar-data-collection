import SwiftUI
import ARKit
import SceneKit

struct ContentView: UIViewRepresentable {
    @State private var depthImage: UIImage?

    func makeUIView(context: Context) -> UIView {
        let containerView = UIView(frame: .zero)
        let arView = ARSCNView(frame: .zero)
        arView.translatesAutoresizingMaskIntoConstraints = false
        containerView.addSubview(arView)

        NSLayoutConstraint.activate([
            arView.topAnchor.constraint(equalTo: containerView.topAnchor),
            arView.bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
            arView.leadingAnchor.constraint(equalTo: containerView.leadingAnchor),
            arView.trailingAnchor.constraint(equalTo: containerView.trailingAnchor)
        ])

        let depthImageView = UIImageView(frame: .zero)
        depthImageView.translatesAutoresizingMaskIntoConstraints = false
        depthImageView.contentMode = .scaleAspectFit
        containerView.addSubview(depthImageView)

        NSLayoutConstraint.activate([
            depthImageView.topAnchor.constraint(equalTo: containerView.topAnchor, constant: 20),
            depthImageView.leadingAnchor.constraint(equalTo: containerView.leadingAnchor, constant: 20),
            depthImageView.widthAnchor.constraint(equalToConstant: 400),
            depthImageView.heightAnchor.constraint(equalToConstant: 400)
        ])

        context.coordinator.depthImageView = depthImageView

        let saveButton = UIButton(type: .system)
        saveButton.setTitle("Save Images", for: .normal)
        saveButton.translatesAutoresizingMaskIntoConstraints = false
        saveButton.addTarget(context.coordinator, action: #selector(Coordinator.saveImages), for: .touchUpInside)
        containerView.addSubview(saveButton)

        NSLayoutConstraint.activate([
            saveButton.bottomAnchor.constraint(equalTo: containerView.bottomAnchor, constant: -20),
            saveButton.centerXAnchor.constraint(equalTo: containerView.centerXAnchor)
        ])

        let configuration = ARWorldTrackingConfiguration()
        configuration.planeDetection = [.horizontal, .vertical]

        // Enable scene depth
        if type(of: configuration).supportsFrameSemantics(.sceneDepth) {
            configuration.frameSemantics.insert(.sceneDepth)
        }

        configureCameraFrameRate(to: 24)
        arView.session.run(configuration)
        // configureCameraExposure()
        configureCameraFrameRate(to: 23)

        arView.delegate = context.coordinator
        arView.session.delegate = context.coordinator // Set session delegate
        context.coordinator.arView = arView
        return containerView
    }
    
    func configureCameraExposure() {
        guard let device = AVCaptureDevice.default(for: .video) else { return }
        
        do {
            try device.lockForConfiguration()
            
            device.exposureMode = .custom
            
            // 设置曝光时间（以秒为单位）
            let exposureDuration = CMTimeMake(value: 1, timescale: 200) // 例如，1/30秒
            
            device.setExposureModeCustom(duration: exposureDuration, iso: AVCaptureDevice.currentISO) { time in
                print("Exposure set to \(time.seconds) seconds")
            }
            
            device.unlockForConfiguration()
            print("Exposure configuration successful")
        } catch {
            print("Error locking configuration: \(error)")
        }
    }

    func configureCameraFrameRate(to fps: Int) {
        guard let device = AVCaptureDevice.default(for: .video) else { return }
        
        do {
            try device.lockForConfiguration()
            // 设置自定义帧率
            let desiredFrameDuration = CMTimeMake(value: 1, timescale: Int32(fps))
            device.activeVideoMinFrameDuration = desiredFrameDuration
            device.activeVideoMaxFrameDuration = desiredFrameDuration
            device.unlockForConfiguration()
            print("fps set to \(fps)")
        } catch {
            print("Error locking configuration: \(error)")
        }
    }


    func updateUIView(_ uiView: UIView, context: Context) {
        // Update the view if needed
    }

    func makeCoordinator() -> Coordinator {
        Coordinator(self)
    }


    class Coordinator: NSObject, ARSCNViewDelegate, ARSessionDelegate {
        var parent: ContentView
        var depthImageView: UIImageView?
        var arView: ARSCNView?
        private var lastFrameTimestamp: TimeInterval?
        private var frameCount: Int = 0
        private var startTime: TimeInterval?

        init(_ parent: ContentView) {
            self.parent = parent
        }

        // Implement ARSCNViewDelegate methods if needed
        func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {
            // Handle new anchors added to the scene
        }

        func session(_ session: ARSession, didFailWithError error: Error) {
            // Handle session errors
        }

        func sessionWasInterrupted(_ session: ARSession) {
            // Handle session interruptions
        }

        func sessionInterruptionEnded(_ session: ARSession) {
            // Handle session interruption end
        }

        // Implement ARSessionDelegate method to capture depth data
        func session(_ session: ARSession, didUpdate frame: ARFrame) {

            let pixelBuffer = frame.capturedImage
            let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
            let context = CIContext()
            if let cgImage = context.createCGImage(ciImage, from: ciImage.extent) {
                let uiImage = UIImage(cgImage: cgImage)
                DispatchQueue.main.async {
                    self.depthImageView?.image = uiImage
                }

                // [fps]
                let currentTime = frame.timestamp
                if let lastTime = lastFrameTimestamp {
                    let deltaTime = currentTime - lastTime
                    let fps = 1.0 / deltaTime
                    // print("Current FPS: \(fps)")
                }
                lastFrameTimestamp = currentTime
            }
        }

        private func displayDepthMap(_ depthMap: CVPixelBuffer) {
            CVPixelBufferLockBaseAddress(depthMap, .readOnly)
            defer { CVPixelBufferUnlockBaseAddress(depthMap, .readOnly) }

            let width = CVPixelBufferGetWidth(depthMap)
            let height = CVPixelBufferGetHeight(depthMap)
            let baseAddress = CVPixelBufferGetBaseAddress(depthMap)!

            // Assuming the depth map is in Float32 format
            let floatBuffer = baseAddress.assumingMemoryBound(to: Float32.self)

            // Convert depth data to UIImage for display
            let depthImage = imageFromDepthMap(floatBuffer, width: width, height: height)

            // Update the depth image view on the main thread
            DispatchQueue.main.async {
                self.depthImageView?.image = depthImage
            }
        }

        private func imageFromDepthMap(_ depthMap: UnsafePointer<Float32>, width: Int, height: Int) -> UIImage {
            // Convert depth map to grayscale image
            let bitsPerComponent = 8
            let bytesPerRow = width
            var pixelData = [UInt8](repeating: 0, count: width * height)
            for y in 0..<height {
                for x in 0..<width {
                    let depthValue = depthMap[y * width + x]
                    let pixelValue = UInt8(min(255.0, depthValue * 255.0)) // Normalize to 0-255
                    pixelData[y * width + x] = pixelValue
                }
            }
            let colorSpace = CGColorSpaceCreateDeviceGray()
            let bitmapInfo = CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue)
            let provider = CGDataProvider(data: NSData(bytes: &pixelData, length: pixelData.count))
            let cgImage = CGImage(width: width, height: height, bitsPerComponent: bitsPerComponent, bitsPerPixel: bitsPerComponent, bytesPerRow: bytesPerRow, space: colorSpace, bitmapInfo: bitmapInfo, provider: provider!, decode: nil, shouldInterpolate: false, intent: .defaultIntent)

            // Correct the orientation and aspect ratio
            let uiImage = UIImage(cgImage: cgImage!)
            let rotatedImage = uiImage.rotate(radians: .pi / 2) // Rotate 90 degrees
            return rotatedImage
        }

        @objc func saveImages() {
            guard let arView = arView else { return }
            guard let currentFrame = arView.session.currentFrame else { return }

            printCenterImageValues(from: currentFrame.capturedImage, label: "ok omg")
            // Capture RGB image
            guard let rgbImage = UIImage(pixelBuffer: currentFrame.capturedImage) else { return }

            // Capture depth image
            if let depthData = currentFrame.sceneDepth {
                let depthMap = depthData.depthMap
                CVPixelBufferLockBaseAddress(depthMap, .readOnly)
                defer { CVPixelBufferUnlockBaseAddress(depthMap, .readOnly) }

                let width = CVPixelBufferGetWidth(depthMap)
                let height = CVPixelBufferGetHeight(depthMap)
                let baseAddress = CVPixelBufferGetBaseAddress(depthMap)!
                let floatBuffer = baseAddress.assumingMemoryBound(to: Float32.self)
                let depthImage = imageFromDepthMap(floatBuffer, width: width, height: height)

                // Save images as JPGs
                saveImage(rgbImage, withName: "rgbImage.jpg")
                saveImage(depthImage, withName: "depthImage.jpg")
            }
        }

        private func saveImage(_ image: UIImage, withName name: String) {
            guard let data = image.jpegData(compressionQuality: 1.0) else { return }
            let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
            let fileURL = documentsDirectory.appendingPathComponent(name)
            do {
                try data.write(to: fileURL)
                print("Saved image to \(fileURL)")
            } catch {
                print("Error saving image: \(error)")
            }
        }

        private func printCenterImageValues(from imageBuffer: CVPixelBuffer, label: String) {
            CVPixelBufferLockBaseAddress(imageBuffer, .readOnly)
            defer { CVPixelBufferUnlockBaseAddress(imageBuffer, .readOnly) }

            let width = CVPixelBufferGetWidth(imageBuffer)
            let height = CVPixelBufferGetHeight(imageBuffer)
            let baseAddress = CVPixelBufferGetBaseAddress(imageBuffer)!

            // Assuming the image is in BGRA format (4 bytes per pixel)
            let buffer = baseAddress.assumingMemoryBound(to: UInt8.self)

            // Calculate the center pixel index
            let centerX = width / 2
            let centerY = height / 2

            // Print the values of the center 3x3 pixels (BGRA format)
            let centerValues = (-1...1).flatMap { yOffset in
                (-1...1).map { xOffset in
                    let pixelOffset = ((centerY + yOffset) * width + (centerX + xOffset)) * 4
                    let b = buffer[pixelOffset]
                    let g = buffer[pixelOffset + 1]
                    let r = buffer[pixelOffset + 2]
                    let a = buffer[pixelOffset + 3]
                    return (b, g, r, a)
                }
            }
            print("\(label) - Center 3x3 pixel values: \(centerValues)")
        }

        private func printFirstRowImageValues(from imageBuffer: CVPixelBuffer, label: String) {
            CVPixelBufferLockBaseAddress(imageBuffer, .readOnly)
            defer { CVPixelBufferUnlockBaseAddress(imageBuffer, .readOnly) }

            let width = CVPixelBufferGetWidth(imageBuffer)
            let baseAddress = CVPixelBufferGetBaseAddress(imageBuffer)!

            // Assuming the image is in BGRA format (4 bytes per pixel)
            let buffer = baseAddress.assumingMemoryBound(to: UInt8.self)

            // Print the first 10 values of the first row (BGRA format)
            let firstRowValues = (0..<min(10, width)).map { index in
                let pixelOffset = index * 4
                let b = buffer[pixelOffset]
                let g = buffer[pixelOffset + 1]
                let r = buffer[pixelOffset + 2]
                let a = buffer[pixelOffset + 3]
                return (b, g, r, a)
            }

            print("\(label) - First 10 values of the first row: \(firstRowValues)")
        }
    }

}

extension UIImage {
    func rotate(radians: CGFloat) -> UIImage {
        let rotatedSize = CGRect(origin: .zero, size: size)
            .applying(CGAffineTransform(rotationAngle: radians))
            .integral.size
        UIGraphicsBeginImageContext(rotatedSize)
        let context = UIGraphicsGetCurrentContext()!
        context.translateBy(x: rotatedSize.width / 2, y: rotatedSize.height / 2)
        context.rotate(by: radians)
        draw(in: CGRect(x: -size.width / 2, y: -size.height / 2, width: size.width, height: size.height))
        let rotatedImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        return rotatedImage!
    }
}

extension UIImage {
    convenience init?(pixelBuffer: CVPixelBuffer) {
        var ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        let context = CIContext()
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else { return nil }
        self.init(cgImage: cgImage)
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}


