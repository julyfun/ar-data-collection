import SwiftUI
import ARKit
import SceneKit
import AVFoundation

struct ContentView: UIViewRepresentable {
    @State private var depthImage: UIImage?

    func makeUIView(context: Context) -> UIView {
        let containerView = UIView(frame: .zero)
        
        // ARKit View
        let arView = ARSCNView(frame: .zero)
        arView.translatesAutoresizingMaskIntoConstraints = false
        containerView.addSubview(arView)

        NSLayoutConstraint.activate([
            arView.topAnchor.constraint(equalTo: containerView.topAnchor),
            arView.bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
            arView.leadingAnchor.constraint(equalTo: containerView.leadingAnchor),
            arView.trailingAnchor.constraint(equalTo: containerView.trailingAnchor)
        ])

        // AVFoundation Preview Layer
        let previewLayer = AVCaptureVideoPreviewLayer(session: context.coordinator.captureSession)
        previewLayer.videoGravity = .resizeAspectFill
        previewLayer.frame = containerView.bounds
        containerView.layer.addSublayer(previewLayer)
        
        // Depth Image View
        let depthImageView = UIImageView(frame: .zero)
        depthImageView.translatesAutoresizingMaskIntoConstraints = false
        depthImageView.contentMode = .scaleAspectFit
        containerView.addSubview(depthImageView)

        NSLayoutConstraint.activate([
            depthImageView.topAnchor.constraint(equalTo: containerView.topAnchor, constant: 20),
            depthImageView.leadingAnchor.constraint(equalTo: containerView.leadingAnchor, constant: 20),
            depthImageView.widthAnchor.constraint(equalToConstant: 400),
            depthImageView.heightAnchor.constraint(equalToConstant: 400)
        ])

        context.coordinator.depthImageView = depthImageView

        // Save Button
        let saveButton = UIButton(type: .system)
        saveButton.setTitle("Save Images", for: .normal)
        saveButton.translatesAutoresizingMaskIntoConstraints = false
        saveButton.addTarget(context.coordinator, action: #selector(Coordinator.saveImages), for: .touchUpInside)
        containerView.addSubview(saveButton)

        NSLayoutConstraint.activate([
            saveButton.bottomAnchor.constraint(equalTo: containerView.bottomAnchor, constant: -20),
            saveButton.centerXAnchor.constraint(equalTo: containerView.centerXAnchor)
        ])

        // ARKit Configuration
        let configuration = ARWorldTrackingConfiguration()
        configuration.planeDetection = [.horizontal, .vertical]

        // Enable scene depth
        if type(of: configuration).supportsFrameSemantics(.sceneDepth) {
            configuration.frameSemantics.insert(.sceneDepth)
        }

        arView.session.run(configuration)
        arView.delegate = context.coordinator
        arView.session.delegate = context.coordinator
        context.coordinator.arView = arView

        // Start AVFoundation Capture Session
        context.coordinator.startCaptureSession()

        return containerView
    }

    func updateUIView(_ uiView: UIView, context: Context) {
        // Update the view if needed
    }

    func makeCoordinator() -> Coordinator {
        Coordinator(self)
    }

    class Coordinator: NSObject, ARSCNViewDelegate, ARSessionDelegate, AVCaptureVideoDataOutputSampleBufferDelegate {
        var parent: ContentView
        var depthImageView: UIImageView?
        var arView: ARSCNView?
        var captureSession: AVCaptureSession
        var lastFrameTimestamp: TimeInterval?

        init(_ parent: ContentView) {
            self.parent = parent
            self.captureSession = AVCaptureSession()
            super.init()
            setupCaptureSession()
        }

        private func setupCaptureSession() {
            captureSession.beginConfiguration()
            guard let videoDevice = AVCaptureDevice.default(.builtInUltraWideCamera, for: .video, position: .back) else { return }
            guard let videoInput = try? AVCaptureDeviceInput(device: videoDevice) else { return }
            if captureSession.canAddInput(videoInput) {
                captureSession.addInput(videoInput)
            }

            let videoOutput = AVCaptureVideoDataOutput()
            videoOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "videoQueue"))
            if captureSession.canAddOutput(videoOutput) {
                captureSession.addOutput(videoOutput)
            }
            captureSession.commitConfiguration()
        }

        func startCaptureSession() {
            captureSession.startRunning()
        }

        func stopCaptureSession() {
            captureSession.stopRunning()
        }

        // ARSCNViewDelegate method to capture depth data
        func session(_ session: ARSession, didUpdate frame: ARFrame) {
            let pixelBuffer = frame.capturedImage
            let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
            let context = CIContext()
            if let cgImage = context.createCGImage(ciImage, from: ciImage.extent) {
                let uiImage = UIImage(cgImage: cgImage)
                DispatchQueue.main.async {
                    self.depthImageView?.image = uiImage
                }

                // [fps]
                let currentTime = frame.timestamp
                if let lastTime = lastFrameTimestamp {
                    let deltaTime = currentTime - lastTime
                    let fps = 1.0 / deltaTime
                    // print("Current FPS: \(fps)")
                }
                lastFrameTimestamp = currentTime
            }

            if let sceneDepth = frame.sceneDepth?.depthMap {
                displayDepthMap(sceneDepth)
            }
        }

        // AVCaptureVideoDataOutputSampleBufferDelegate method to capture ultra-wide camera data
        func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
            let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
            let context = CIContext()
            if let cgImage = context.createCGImage(ciImage, from: ciImage.extent) {
                let uiImage = UIImage(cgImage: cgImage)
                DispatchQueue.main.async {
                    // You can update a different UIImageView or handle the image as needed
                }
            }
        }

        private func displayDepthMap(_ depthMap: CVPixelBuffer) {
            CVPixelBufferLockBaseAddress(depthMap, .readOnly)
            defer { CVPixelBufferUnlockBaseAddress(depthMap, .readOnly) }

            let width = CVPixelBufferGetWidth(depthMap)
            let height = CVPixelBufferGetHeight(depthMap)
            let baseAddress = CVPixelBufferGetBaseAddress(depthMap)!

            // Assuming the depth map is in Float32 format
            let floatBuffer = baseAddress.assumingMemoryBound(to: Float32.self)

            // Convert depth data to UIImage for display
            let depthImage = imageFromDepthMap(floatBuffer, width: width, height: height)

            // Update the depth image view on the main thread
            DispatchQueue.main.async {
                self.depthImageView?.image = depthImage
            }
        }

        private func imageFromDepthMap(_ depthMap: UnsafePointer<Float32>, width: Int, height: Int) -> UIImage {
            // Convert depth map to grayscale image
            let bitsPerComponent = 8
            let bytesPerRow = width
            var pixelData = [UInt8](repeating: 0, count: width * height)

            for y in 0..<height {
                for x in 0..<width {
                    let depth = depthMap[y * width + x]
                    let normalizedDepth = UInt8(clamping: (depth * 255.0).rounded())
                    pixelData[y * width + x] = normalizedDepth
                }
            }

            let colorSpace = CGColorSpaceCreateDeviceGray()
            let bitmapInfo = CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue)
            let provider = CGDataProvider(data: Data(pixelData) as CFData)!

            let cgImage = CGImage(
                width: width,
                height: height,
                bitsPerComponent: bitsPerComponent,
                bitsPerPixel: bitsPerComponent,
                bytesPerRow: bytesPerRow,
                space: colorSpace,
                bitmapInfo: bitmapInfo,
                provider: provider,
                decode: nil,
                shouldInterpolate: false,
                intent: .defaultIntent
            )

            return UIImage(cgImage: cgImage!)
        }

        @objc func saveImages() {
            // Implement save image functionality if needed
        }
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}


